{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informal-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import pandas as pd\n",
    "data_path = 'data.csv'\n",
    "data= pd.read_csv(data_path)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "generic-mexican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>71</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race/ethnicity parental level of education         lunch  \\\n",
       "1    female        group C                some college      standard   \n",
       "2    female        group B             master's degree      standard   \n",
       "3      male        group A          associate's degree  free/reduced   \n",
       "4      male        group C                some college      standard   \n",
       "5    female        group B          associate's degree      standard   \n",
       "..      ...            ...                         ...           ...   \n",
       "995  female        group E             master's degree      standard   \n",
       "996    male        group C                 high school  free/reduced   \n",
       "997  female        group C                 high school  free/reduced   \n",
       "998  female        group D                some college      standard   \n",
       "999  female        group D                some college  free/reduced   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \n",
       "1                 completed          69             90             88  \n",
       "2                      none          90             95             93  \n",
       "3                      none          47             57             44  \n",
       "4                      none          76             78             75  \n",
       "5                      none          71             83             78  \n",
       "..                      ...         ...            ...            ...  \n",
       "995               completed          88             99             95  \n",
       "996                    none          62             55             55  \n",
       "997               completed          59             71             65  \n",
       "998               completed          68             78             77  \n",
       "999                    none          77             86             86  \n",
       "\n",
       "[999 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "tired-marble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>67</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>29</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>55</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>70</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender  race/ethnicity  parental level of education  lunch  \\\n",
       "1         0               2                            4      1   \n",
       "2         0               1                            3      1   \n",
       "3         1               0                            0      0   \n",
       "4         1               2                            4      1   \n",
       "5         0               1                            0      1   \n",
       "..      ...             ...                          ...    ...   \n",
       "995       0               4                            3      1   \n",
       "996       1               2                            2      0   \n",
       "997       0               2                            2      0   \n",
       "998       0               3                            4      1   \n",
       "999       0               3                            4      0   \n",
       "\n",
       "     test preparation course  math score  reading score  writing score  \n",
       "1                          0          49             62             64  \n",
       "2                          1          70             67             69  \n",
       "3                          1          27             29             20  \n",
       "4                          1          56             50             51  \n",
       "5                          1          51             55             54  \n",
       "..                       ...         ...            ...            ...  \n",
       "995                        0          68             70             71  \n",
       "996                        1          42             27             31  \n",
       "997                        0          39             43             41  \n",
       "998                        0          48             50             53  \n",
       "999                        1          57             58             62  \n",
       "\n",
       "[999 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data[col] = labelencoder.fit_transform(data[col])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2eebd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import random\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d621868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_f, out_f, activate=2):\n",
    "        super().__init__()\n",
    "        a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "        net = [\n",
    "            nn.Linear(in_f, out_f),\n",
    "            a[activate],\n",
    "            nn.BatchNorm1d(out_f)\n",
    "        ]\n",
    "        self.net = nn.Sequential(*net)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "# def MLP_model(num_layers, hidden_dim,activate):\n",
    "#     a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "#     layers = []\n",
    "#     for i in range(num_layers):\n",
    "#         layers.append(LinearLayer(hidden_dim[i], hidden_dim[i+1]))\n",
    "#         layers.append(a[activate])\n",
    "#         layers.append(nn.BatchNorm1d(hidden_dim[i+1]))\n",
    "#         if i < num_layers - 1:\n",
    "#             layers.append(nn.Dropout(0.2))\n",
    "#     #layers.append(nn.Softmax(dim=1))\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "class MLP_model(nn.Module):\n",
    "    def __init__(self, nomask_dims, mask_dims, share_dims, activate=2):\n",
    "        super().__init__()\n",
    "        a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "        \n",
    "        nomask_layers = []\n",
    "        for i in range(len(nomask_dims) - 1):\n",
    "            nomask_layers.append(LinearLayer(nomask_dims[i], nomask_dims[i + 1], activate))\n",
    "        self.nomask_layers = nn.Sequential(*nomask_layers)\n",
    "        \n",
    "        mask_layers = []\n",
    "        for i in range(len(mask_dims) - 1):\n",
    "            mask_layers.append(LinearLayer(mask_dims[i], mask_dims[i + 1], activate))\n",
    "        self.mask_layers = nn.Sequential(*mask_layers)\n",
    "        \n",
    "        share_layers = []\n",
    "        share_layers.append(LinearLayer(mask_dims[-1] + nomask_dims[-1], share_dims[0], activate))\n",
    "        for i in range(len(share_dims) - 1):\n",
    "            share_layers.append(LinearLayer(share_dims[i], share_dims[i + 1], activate))\n",
    "        self.share_layers = nn.Sequential(*share_layers)\n",
    "    \n",
    "    def forward(self, nomask_input, mask_input):\n",
    "        x = self.nomask_layers(nomask_input)\n",
    "        mask = torch.ones_like(mask_input).to(mask_input.device)\n",
    "        mask_type = [[0],[1],[2],[0,1],[0,2],[1,2],[0,1,2]]\n",
    "        for i in range(mask.shape[0]):\n",
    "            mask[i, mask_type[random.randint(0, 6)]] = 1\n",
    "        mask = torch.randint(2, mask_input.shape).to(mask_input.device)\n",
    "        y = self.mask_layers(mask_input * mask)\n",
    "        mid = torch.cat((x, y), dim=-1)\n",
    "        out = self.share_layers(mid)\n",
    "        return out\n",
    "        \n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "differential-store",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161046/1952557141.py:98: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = torch.tensor(np.load('data.npy', allow_pickle=True).astype(np.float)).to(torch.device('cuda:0'))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178b83c05c704de0827f4b301d7f7740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                   | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161046/1952557141.py:46: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  ground_truth = ((batch[0][:,5] + batch[0][:, 6] + batch[0][:, 7]) // 100).long().to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集输出结果:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161046/1952557141.py:74: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  a[int((batch[0][0][5] + batch[0][0][6] + batch[0][0][7]) // 100), torch.argmax(out_put, dim=1)] += 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168.  16.   0.]\n",
      " [ 12. 570.   0.]\n",
      " [  0.  12.  22.]]\n",
      "准确率0.95\n",
      "测试集输出结果:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2161046/1952557141.py:85: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  a[int((batch[0][0][5] + batch[0][0][6] + batch[0][0][7]) // 100), torch.argmax(out_put, dim=1)] += 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 36.   9.   0.]\n",
      " [  6. 134.   1.]\n",
      " [  0.   5.   8.]]\n",
      "准确率0.8944723618090452\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    data=pd.read_csv(data_path)\n",
    "    labelencoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        data[col] = labelencoder.fit_transform(data[col])\n",
    "    data.head()\n",
    "    np.save(\"data\", data[1:])\n",
    "\n",
    "\n",
    "def get_dataset(data):   \n",
    "    train_dataset = []\n",
    "    test_dataset = []\n",
    "    for i in range(data.shape[0]):\n",
    "        if i < data.shape[0] * 0.8:\n",
    "            train_dataset.append(data[i])\n",
    "        else:\n",
    "            test_dataset.append(data[i])\n",
    "\n",
    "    train_dataset = TensorDataset(torch.cat(train_dataset).reshape(-1, 8))\n",
    "    test_dataset = TensorDataset(torch.cat(test_dataset).reshape(-1, 8))\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "\n",
    "def train():\n",
    "    writer = SummaryWriter('log')\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()    \n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=2000,\n",
    "                                                               verbose=True, threshold=0.002, threshold_mode='rel',\n",
    "                                                               cooldown=2000)\n",
    "    \n",
    "    step = 0\n",
    "    pbar = tqdm(range(epoch), initial=0, dynamic_ncols=True, smoothing=0.01)\n",
    "    for i in pbar:\n",
    "        # break\n",
    "        for j, batch in enumerate(train_loader):            \n",
    "            optim.zero_grad()\n",
    "            # input = batch[:, 2:15].float()\n",
    "            # pdb.set_trace()\n",
    "            nomask_input = batch[0][:, 0:5].float().to(device)\n",
    "            mask_input = batch[0][:, 5:8].float().to(device)\n",
    "            ground_truth = ((batch[0][:,5] + batch[0][:, 6] + batch[0][:, 7]) // 100).long().to(device)\n",
    "            out_put = model(nomask_input, mask_input)\n",
    "            loss = loss_fn(out_put, ground_truth)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            writer.add_scalar('loss', loss, step)\n",
    "            \n",
    "            pbar.set_description(\n",
    "                        (\n",
    "                            f'iter: {step} loss: {loss:.4f}'\n",
    "                        )\n",
    "                    )\n",
    "            step += 1\n",
    "    torch.save(model, f\"model/model.pth\")\n",
    "\n",
    "def test():\n",
    "    model=torch.load(\"model/model.pth\").to(torch.device('cuda:0'))\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"训练集输出结果:\")\n",
    "    a = np.zeros(shape=(3, 3))\n",
    "    dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        nomask_input = batch[0][:, 0:5].float().to(device)\n",
    "        mask_input = batch[0][:, 5:8].float().to(device)\n",
    "        out_put = model(nomask_input, mask_input)\n",
    "        a[int((batch[0][0][5] + batch[0][0][6] + batch[0][0][7]) // 100), torch.argmax(out_put, dim=1)] += 1\n",
    "    print(a)\n",
    "    print(f'准确率{(a[0][0] + a[1][1] + a[2][2]) / len(train_dataset)}')\n",
    "    \n",
    "    print(\"测试集输出结果:\")\n",
    "    a = np.zeros(shape=(3, 3))\n",
    "    dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        nomask_input = batch[0][:, 0:5].float().to(device)\n",
    "        mask_input = batch[0][:, 5:8].float().to(device)\n",
    "        out_put = model(nomask_input, mask_input)\n",
    "        a[int((batch[0][0][5] + batch[0][0][6] + batch[0][0][7]) // 100), torch.argmax(out_put, dim=1)] += 1\n",
    "    print(a)\n",
    "    print(f'准确率{(a[0][0] + a[1][1] + a[2][2]) / len(test_dataset)}')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    read_data()\n",
    "    epoch = 200 # setting epoch of train\n",
    "    nomask_dims = [5, 64, 128, 256]\n",
    "    mask_dims = [3, 64, 128]\n",
    "    share_dims = [512, 256, 128, 64, 3]\n",
    "    activate = 2  # setting the activate function of net\n",
    "    learning_rate = 0.001  # setting learning_rate\n",
    "    \n",
    "    data = torch.tensor(np.load('data.npy', allow_pickle=True).astype(np.float)).to(torch.device('cuda:0'))\n",
    "    train_dataset, test_dataset = get_dataset(data) \n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = MLP_model(nomask_dims, mask_dims, share_dims, activate).to(device)\n",
    "    model.apply(init_weights)\n",
    "    # model=torch.load(\"model/model.pth\").to(torch.device('cuda:0'))\n",
    "    train()\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7145965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
