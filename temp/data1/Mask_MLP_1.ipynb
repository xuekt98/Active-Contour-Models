{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informal-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取数据\n",
    "import pandas as pd\n",
    "data_path = 'data.csv'\n",
    "data= pd.read_csv(data_path)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-mexican",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continue_drop</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>caste</th>\n",
       "      <th>mathematics_marks</th>\n",
       "      <th>english_marks</th>\n",
       "      <th>science_marks</th>\n",
       "      <th>science_teacher</th>\n",
       "      <th>languages_teacher</th>\n",
       "      <th>guardian</th>\n",
       "      <th>internet</th>\n",
       "      <th>school_id</th>\n",
       "      <th>total_students</th>\n",
       "      <th>total_toilets</th>\n",
       "      <th>establishment_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00002</td>\n",
       "      <td>F</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.290</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>328</td>\n",
       "      <td>356</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00003</td>\n",
       "      <td>F</td>\n",
       "      <td>OC</td>\n",
       "      <td>0.602</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.602</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>mother</td>\n",
       "      <td>False</td>\n",
       "      <td>322</td>\n",
       "      <td>179</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1955.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00004</td>\n",
       "      <td>F</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.378</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>305</td>\n",
       "      <td>354</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00005</td>\n",
       "      <td>F</td>\n",
       "      <td>OC</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.536</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>360</td>\n",
       "      <td>273</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1995.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>continue</td>\n",
       "      <td>s00006</td>\n",
       "      <td>F</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.594</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>333</td>\n",
       "      <td>335</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1916.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>continue</td>\n",
       "      <td>s19096</td>\n",
       "      <td>M</td>\n",
       "      <td>OC</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.323</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>320</td>\n",
       "      <td>384</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1909.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>continue</td>\n",
       "      <td>s19097</td>\n",
       "      <td>M</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.633</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>mother</td>\n",
       "      <td>True</td>\n",
       "      <td>378</td>\n",
       "      <td>121</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>continue</td>\n",
       "      <td>s19098</td>\n",
       "      <td>M</td>\n",
       "      <td>SC</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.337</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>378</td>\n",
       "      <td>121</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>continue</td>\n",
       "      <td>s19099</td>\n",
       "      <td>M</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.344</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>other</td>\n",
       "      <td>True</td>\n",
       "      <td>374</td>\n",
       "      <td>207</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>continue</td>\n",
       "      <td>s19100</td>\n",
       "      <td>M</td>\n",
       "      <td>BC</td>\n",
       "      <td>0.183</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.183</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>mother</td>\n",
       "      <td>False</td>\n",
       "      <td>343</td>\n",
       "      <td>353</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19099 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      continue_drop student_id gender caste  mathematics_marks  english_marks  \\\n",
       "1          continue     s00002      F    BC              0.290          0.512   \n",
       "2          continue     s00003      F    OC              0.602          0.666   \n",
       "3          continue     s00004      F    BC              0.378          0.526   \n",
       "4          continue     s00005      F    OC              0.536          0.614   \n",
       "5          continue     s00006      F    BC              0.594          0.519   \n",
       "...             ...        ...    ...   ...                ...            ...   \n",
       "19095      continue     s19096      M    OC              0.323          0.429   \n",
       "19096      continue     s19097      M    BC              0.633          0.885   \n",
       "19097      continue     s19098      M    SC              0.337          0.283   \n",
       "19098      continue     s19099      M    BC              0.344          0.351   \n",
       "19099      continue     s19100      M    BC              0.183          0.077   \n",
       "\n",
       "       science_marks  science_teacher  languages_teacher guardian  internet  \\\n",
       "1              0.290                4                  7   mother      True   \n",
       "2              0.602                4                  2   mother     False   \n",
       "3              0.378                8                  7   mother      True   \n",
       "4              0.536                9                  4    other      True   \n",
       "5              0.594                4                  8   mother      True   \n",
       "...              ...              ...                ...      ...       ...   \n",
       "19095          0.323                2                  7   mother      True   \n",
       "19096          0.633                6                  2   mother      True   \n",
       "19097          0.337                2                  6    other      True   \n",
       "19098          0.344                6                  0    other      True   \n",
       "19099          0.183                4                  6   mother     False   \n",
       "\n",
       "       school_id  total_students  total_toilets  establishment_year  \n",
       "1            328             356           14.0              1943.0  \n",
       "2            322             179            8.0              1955.0  \n",
       "3            305             354           86.0              1986.0  \n",
       "4            360             273            2.0              1995.0  \n",
       "5            333             335           43.0              1916.0  \n",
       "...          ...             ...            ...                 ...  \n",
       "19095        320             384           28.0              1909.0  \n",
       "19096        378             121           28.0              1971.0  \n",
       "19097        378             121           28.0              1971.0  \n",
       "19098        374             207           28.0              1896.0  \n",
       "19099        343             353           15.0              1957.0  \n",
       "\n",
       "[19099 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "tired-marble",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continue_drop</th>\n",
       "      <th>student_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>caste</th>\n",
       "      <th>mathematics_marks</th>\n",
       "      <th>english_marks</th>\n",
       "      <th>science_marks</th>\n",
       "      <th>science_teacher</th>\n",
       "      <th>languages_teacher</th>\n",
       "      <th>guardian</th>\n",
       "      <th>internet</th>\n",
       "      <th>school_id</th>\n",
       "      <th>total_students</th>\n",
       "      <th>total_toilets</th>\n",
       "      <th>establishment_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>110</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>203</td>\n",
       "      <td>187</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>122</td>\n",
       "      <td>86</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>21</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>174</td>\n",
       "      <td>157</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185</td>\n",
       "      <td>115</td>\n",
       "      <td>185</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>73</td>\n",
       "      <td>14</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19095</th>\n",
       "      <td>0</td>\n",
       "      <td>19094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19096</th>\n",
       "      <td>0</td>\n",
       "      <td>19095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>276</td>\n",
       "      <td>200</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19097</th>\n",
       "      <td>0</td>\n",
       "      <td>19096</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>18</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>28</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19098</th>\n",
       "      <td>0</td>\n",
       "      <td>19097</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>36</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>54</td>\n",
       "      <td>11</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19099</th>\n",
       "      <td>0</td>\n",
       "      <td>19098</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>75</td>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19099 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       continue_drop  student_id  gender  caste  mathematics_marks  \\\n",
       "1                  0           0       0      0                 48   \n",
       "2                  0           1       0      1                187   \n",
       "3                  0           2       0      0                 86   \n",
       "4                  0           3       0      1                157   \n",
       "5                  0           4       0      0                185   \n",
       "...              ...         ...     ...    ...                ...   \n",
       "19095              0       19094       1      1                 58   \n",
       "19096              0       19095       1      0                200   \n",
       "19097              0       19096       1      2                 63   \n",
       "19098              0       19097       1      0                 67   \n",
       "19099              0       19098       1      0                 26   \n",
       "\n",
       "       english_marks  science_marks  science_teacher  languages_teacher  \\\n",
       "1                110             48                4                  7   \n",
       "2                203            187                4                  2   \n",
       "3                122             86                8                  7   \n",
       "4                174            157                9                  4   \n",
       "5                115            185                4                  8   \n",
       "...              ...            ...              ...                ...   \n",
       "19095             64             58                2                  7   \n",
       "19096            276            200                6                  2   \n",
       "19097             18             63                2                  6   \n",
       "19098             36             67                6                  0   \n",
       "19099              0             26                4                  6   \n",
       "\n",
       "       guardian  internet  school_id  total_students  total_toilets  \\\n",
       "1             2         1         28              77              6   \n",
       "2             2         0         22              46              4   \n",
       "3             2         1          5              76             21   \n",
       "4             3         1         60              65              1   \n",
       "5             2         1         33              73             14   \n",
       "...         ...       ...        ...             ...            ...   \n",
       "19095         2         1         20              79             11   \n",
       "19096         2         1         78              28             11   \n",
       "19097         3         1         78              28             11   \n",
       "19098         3         1         74              54             11   \n",
       "19099         2         0         43              75              7   \n",
       "\n",
       "       establishment_year  \n",
       "1                      42  \n",
       "2                      48  \n",
       "3                      65  \n",
       "4                      68  \n",
       "5                      31  \n",
       "...                   ...  \n",
       "19095                  25  \n",
       "19096                  57  \n",
       "19097                  57  \n",
       "19098                  17  \n",
       "19099                  50  \n",
       "\n",
       "[19099 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "for col in data.columns:\n",
    "    data[col] = labelencoder.fit_transform(data[col])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2eebd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "from tqdm.autonotebook import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d621868",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_f, out_f, activate=2):\n",
    "        super().__init__()\n",
    "        a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "        net = [\n",
    "            nn.Linear(in_f, out_f),\n",
    "            a[activate],\n",
    "            nn.BatchNorm1d(out_f)\n",
    "        ]\n",
    "        self.net = nn.Sequential(*net)\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return x\n",
    "\n",
    "# def MLP_model(num_layers, hidden_dim,activate):\n",
    "#     a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "#     layers = []\n",
    "#     for i in range(num_layers):\n",
    "#         layers.append(LinearLayer(hidden_dim[i], hidden_dim[i+1]))\n",
    "#         layers.append(a[activate])\n",
    "#         layers.append(nn.BatchNorm1d(hidden_dim[i+1]))\n",
    "#         if i < num_layers - 1:\n",
    "#             layers.append(nn.Dropout(0.2))\n",
    "#     #layers.append(nn.Softmax(dim=1))\n",
    "#     return nn.Sequential(*layers)\n",
    "\n",
    "class MLP_model(nn.Module):\n",
    "    def __init__(self, nomask_dims, mask_dims, share_dims, activate=2):\n",
    "        super().__init__()\n",
    "        a = [torch.nn.Sigmoid(),torch.nn.Tanh(),torch.nn.LeakyReLU()]\n",
    "        \n",
    "        nomask_layers = []\n",
    "        for i in range(len(nomask_dims) - 1):\n",
    "            nomask_layers.append(LinearLayer(nomask_dims[i], nomask_dims[i + 1], activate))\n",
    "        self.nomask_layers = nn.Sequential(*nomask_layers)\n",
    "        \n",
    "        mask_layers = []\n",
    "        for i in range(len(mask_dims) - 1):\n",
    "            mask_layers.append(LinearLayer(mask_dims[i], mask_dims[i + 1], activate))\n",
    "        self.mask_layers = nn.Sequential(*mask_layers)\n",
    "        \n",
    "        share_layers = []\n",
    "        share_layers.append(LinearLayer(mask_dims[-1] + nomask_dims[-1], share_dims[0], activate))\n",
    "        for i in range(len(share_dims) - 1):\n",
    "            share_layers.append(LinearLayer(share_dims[i], share_dims[i + 1], activate))\n",
    "        self.share_layers = nn.Sequential(*share_layers)\n",
    "    \n",
    "    def forward(self, nomask_input, mask_input):\n",
    "        x = self.nomask_layers(nomask_input)\n",
    "        mask = torch.randint(2, mask_input.shape).to(mask_input.device)\n",
    "        y = self.mask_layers(mask_input * mask)\n",
    "        mid = torch.cat((x, y), dim=-1)\n",
    "        out = self.share_layers(mid)\n",
    "        return out\n",
    "        \n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, std=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "differential-store",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1520073/1168847178.py:122: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  data = torch.tensor(np.load('data.npy', allow_pickle=True).astype(np.float)).to(torch.device('cuda:0'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集输出结果:\n",
      "[[1.4497e+04 6.3000e+01]\n",
      " [1.0000e+00 7.1900e+02]]\n",
      "准确率0.9958115183246073\n",
      "测试集输出结果:\n",
      "[[3623.   16.]\n",
      " [   0.  180.]]\n",
      "准确率0.9958104215763289\n"
     ]
    }
   ],
   "source": [
    "def read_data():\n",
    "    data=pd.read_csv(data_path)\n",
    "    labelencoder = LabelEncoder()\n",
    "    for col in data.columns:\n",
    "        data[col] = labelencoder.fit_transform(data[col])\n",
    "    data.head()\n",
    "    np.save(\"data\", data[1:])\n",
    "\n",
    "\n",
    "def get_dataset(data):\n",
    "    data_class = [[], []]\n",
    "    for i in range(data.shape[0]):\n",
    "        data_class[data[i][0].long()].append(data[i])\n",
    "    \n",
    "    train_dataset = [[], []]\n",
    "    test_dataset = []\n",
    "    for i in range(len(data_class[0])):\n",
    "        if i < len(data_class[0]) * 0.8:\n",
    "            train_dataset[0].append(data_class[0][i])\n",
    "        else:\n",
    "            test_dataset.append(data_class[0][i])\n",
    "            \n",
    "    for i in range(len(data_class[1])):\n",
    "        if i < len(data_class[1]) * 0.8:\n",
    "            train_dataset[1].append(data_class[1][i])\n",
    "        else:\n",
    "            test_dataset.append(data_class[1][i])\n",
    "    train_dataset_con = TensorDataset(torch.cat(train_dataset[0]).reshape(-1, 15))\n",
    "    train_dataset_drop = TensorDataset(torch.cat(train_dataset[1]).reshape(-1, 15))\n",
    "    train_dataset_all = TensorDataset(torch.cat(train_dataset[0] + train_dataset[1]).reshape(-1, 15))\n",
    "    test_dataset_all = TensorDataset(torch.cat(test_dataset).reshape(-1, 15))\n",
    "    return train_dataset_con, train_dataset_drop, train_dataset_all, test_dataset_all\n",
    "\n",
    "\n",
    "def train():\n",
    "    writer = SummaryWriter('log')\n",
    "    model.train()\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()    \n",
    "    \n",
    "    train_loader_con = DataLoader(train_dataset_con, batch_size=96, shuffle=True)\n",
    "    train_loader_drop = iter(DataLoader(train_dataset_drop, batch_size=32, shuffle=True))\n",
    "    \n",
    "    size = len(train_dataset_con) + len(train_dataset_drop)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optim, mode='min', factor=0.5, patience=2000,\n",
    "                                                               verbose=True, threshold=0.002, threshold_mode='rel',\n",
    "                                                               cooldown=2000)\n",
    "    \n",
    "    step = 0\n",
    "    pbar = tqdm(range(epoch), initial=0, dynamic_ncols=True, smoothing=0.01)\n",
    "    for i in pbar:\n",
    "        # break\n",
    "        for j, batch_con in enumerate(train_loader_con):\n",
    "            try:\n",
    "                batch_drop = next(train_loader_drop)\n",
    "            except:\n",
    "                del train_loader_drop\n",
    "                train_loader_drop = iter(DataLoader(train_dataset_drop, batch_size=32, shuffle=True)) \n",
    "                batch_drop = next(train_loader_drop)\n",
    "            \n",
    "            batch = torch.cat(batch_drop, dim=0)\n",
    "            # pdb.set_trace()\n",
    "            batch = torch.cat((batch, batch_con[0]), dim=0)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            # input = batch[:, 2:15].float()\n",
    "            nomask_input = batch[:, [2,3,7,8,9,10,11,12,13,14]].float().to(device)\n",
    "            mask_input = batch[:, 4:7].float().to(device)\n",
    "            ground_truth = batch[:,0].long().to(device)\n",
    "            out_put = model(nomask_input, mask_input)\n",
    "            loss = loss_fn(out_put, ground_truth)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            scheduler.step(loss)\n",
    "            \n",
    "            writer.add_scalar('loss', loss, step)\n",
    "            \n",
    "            pbar.set_description(\n",
    "                        (\n",
    "                            f'iter: {step} loss: {loss:.4f}'\n",
    "                        )\n",
    "                    )\n",
    "            step += 1\n",
    "    torch.save(model, f\"model/model.pth\")\n",
    "\n",
    "def test():\n",
    "    model=torch.load(\"model/model.pth\").to(torch.device('cuda:0'))\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"训练集输出结果:\")\n",
    "    a = np.zeros(shape=(2, 2))\n",
    "    dataloader = DataLoader(train_dataset_all, batch_size=1, shuffle=True)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        nomask_input = batch[0][:, [2,3,7,8,9,10,11,12,13,14]].float().to(device)\n",
    "        mask_input = batch[0][:, 4:7].float().to(device)\n",
    "        out_put = model(nomask_input, mask_input)\n",
    "        a[int(batch[0][0][0]), torch.argmax(out_put, dim=1)] += 1\n",
    "    print(a)\n",
    "    print(f'准确率{(a[0][0] + a[1][1]) / len(train_dataset_all)}')\n",
    "    \n",
    "    print(\"测试集输出结果:\")\n",
    "    a = np.zeros(shape=(2, 2))\n",
    "    dataloader = DataLoader(test_dataset_all, batch_size=1, shuffle=True)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        nomask_input = batch[0][:, [2,3,7,8,9,10,11,12,13,14]].float().to(device)\n",
    "        mask_input = batch[0][:, 4:7].float().to(device)\n",
    "        out_put = model(nomask_input, mask_input)\n",
    "        a[int(batch[0][0][0]), torch.argmax(out_put, dim=1)] += 1\n",
    "    print(a)\n",
    "    print(f'准确率{(a[0][0] + a[1][1]) / len(test_dataset_all)}')\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    read_data()\n",
    "    epoch = 50 # setting epoch of train\n",
    "    nomask_dims = [10, 64, 128, 256]\n",
    "    mask_dims = [3, 64, 128]\n",
    "    share_dims = [512, 256, 128, 64, 2]\n",
    "    activate = 2  # setting the activate function of net\n",
    "    learning_rate = 0.01  # setting learning_rate\n",
    "    \n",
    "    data = torch.tensor(np.load('data.npy', allow_pickle=True).astype(np.float)).to(torch.device('cuda:0'))\n",
    "    train_dataset_con, train_dataset_drop, train_dataset_all, test_dataset_all = get_dataset(data) \n",
    "    \n",
    "    device = torch.device('cuda:0')\n",
    "    model = MLP_model(nomask_dims, mask_dims, share_dims, activate).to(device)\n",
    "    model.apply(init_weights)\n",
    "    # model=torch.load(\"model/model.pth\").to(torch.device('cuda:0'))\n",
    "    # train()\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7145965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
